# Proyecto Final de Deep Learning: Desenvolviendo el Sonido en la Universidad del Valle de Guatemala

> Este trabajo se basa en el proyecto [Music Source Separation](https://github.com/andabi/music-source-separation) desarrollado durante el [Jeju Machine Learning Camp 2017](http://mlcampjeju.kakao.com). Sin embargo, ha sido extensamente modificado y mejorado como parte del proyecto final para la Universidad del Valle de Guatemala por Ale G√≥mez, Michy Solano, Andrea Lam, Chris Garc√≠a, Gabo Vicente y Rodri Barrera.

## Introducci√≥n üéµ

La separaci√≥n de fuentes musicales es una tarea esencial en el procesamiento de se√±ales de audio, que se centra en separar diferentes componentes de una canci√≥n, como la voz y los instrumentos. Este proyecto busca mejorar la arquitectura y la eficacia del modelo inicial propuesto en el repositorio base, explorando t√©cnicas avanzadas en redes neuronales y procesamiento de se√±ales.

## Cambios y Mejoras Realizadas üõ†Ô∏è

### Optimizaci√≥n de la Arquitectura Neural:

- Se experiment√≥ con diferentes configuraciones de las capas RNN y CNN, incluyendo la incorporaci√≥n de mecanismos de atenci√≥n para mejorar la captura de caracter√≠sticas temporales y espaciales.
- Implementaci√≥n de una arquitectura de red neuronal h√≠brida que integra caracter√≠sticas de CNNs para el procesamiento de caracter√≠sticas espaciales y RNNs (LSTM) para la captura de dependencias temporales.

### Funciones de P√©rdida Personalizadas:

- Dise√±o de nuevas funciones de p√©rdida que se alinean mejor con la tarea de separaci√≥n de fuentes, enfoc√°ndose en minimizar la interferencia entre la se√±al vocal e instrumental.

### T√©cnicas de Regularizaci√≥n y Optimizaci√≥n:

- Implementaci√≥n de t√©cnicas de regularizaci√≥n como Dropout y Normalizaci√≥n de Lotes para prevenir el sobreajuste.
- Utilizaci√≥n de optimizadores avanzados y ajuste de hiperpar√°metros para mejorar la convergencia del entrenamiento.

### Utilizaci√≥n de Modelos Pre-entrenados y Fine-tuning:

- Exploraci√≥n de modelos pre-entrenados en tareas de separaci√≥n de fuentes y realizaci√≥n de fine-tuning para adaptar estos modelos a nuestro dataset espec√≠fico, acelerando el entrenamiento y mejorando el rendimiento inicial.

### Comparativas con Herramientas Existentes:

- Comparaci√≥n de rendimiento con herramientas existentes como Splitter AI, validando las mejoras implementadas y proporcionando un benchmark sobre el estado del arte.

### Actualizaci√≥n de Dependencias:

- Actualizaci√≥n de las dependencias a versiones m√°s recientes como TensorFlow 2.x y Librosa 0.8.x, y asegurando la compatibilidad del c√≥digo con estas nuevas versiones.

## Evaluaci√≥n y M√©tricas üìä

- Utilizaci√≥n de m√©tricas est√°ndar en la tarea de separaci√≥n de fuentes como SDR, SIR y SAR, adem√°s de otras m√©tricas relevantes como la precisi√≥n y la recall en la detecci√≥n de componentes vocales e instrumentales.
- Documentaci√≥n meticulosa de los resultados obtenidos, incluyendo visualizaciones de espectrogramas y comparativas cualitativas.

## Conclusi√≥n üéâ

Las mejoras y modificaciones realizadas en este proyecto buscan no solo mejorar el rendimiento en la tarea de separaci√≥n de fuentes de audio, sino tambi√©n proporcionar una implementaci√≥n m√°s robusta y actualizada, demostrando la aplicabilidad de las t√©cnicas de Deep Learning en el procesamiento de se√±ales de audio.

## Cr√©ditos üôå

- Este proyecto fue desarrollado como parte del proyecto final de Deep Learning en la Universidad del Valle de Guatemala por Ale G√≥mez, Michy Solano, Andrea Lam, Chris Garc√≠a, Gabo Vicente y Rodri Barrera.
- Agradecemos a los autores originales del repositorio base, as√≠ como a los instructores y compa√±eros de clase por su apoyo y orientaci√≥n durante el desarrollo de este proyecto.
